{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat, wavfile\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from Signal_Analysis.features.signal import get_F_0, get_HNR\n",
    "from importlib import reload\n",
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer,SetLogLevel\n",
    "import os.path\n",
    "import math\n",
    "from folderFunctions import*\n",
    "\n",
    "\n",
    "# tools work in progress\n",
    "import tools\n",
    "reload(tools)\n",
    "from tools import *\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "mpl.rcParams[\"lines.linewidth\"] = 0.5\n",
    "plt.close(\"all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = \"models/vosk-model-en-us-0.22\"\n",
    "#model_path = \"models/vosk-model-small-en-us-0.15\"\n",
    "model_path = \"models/vosk-model-small-sv-rhasspy-0.15/\"\n",
    "if not \"model\" in locals():\n",
    "    model = Model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Word:\n",
    "    ''' A class representing a word from the JSON format for vosk speech recognition API '''\n",
    "\n",
    "    def __init__(self, dict):\n",
    "        '''\n",
    "        Parameters:\n",
    "          dict (dict) dictionary from JSON, containing:\n",
    "            conf (float): degree of confidence, from 0 to 1\n",
    "            end (float): end time of the pronouncing the word, in seconds\n",
    "            start (float): start time of the pronouncing the word, in seconds\n",
    "            word (str): recognized word\n",
    "        '''\n",
    "\n",
    "        self.conf = dict[\"conf\"]\n",
    "        self.end = dict[\"end\"]\n",
    "        self.start = dict[\"start\"]\n",
    "        self.word = dict[\"word\"]\n",
    "\n",
    "    def to_string(self):\n",
    "        ''' Returns a string describing this instance '''\n",
    "        return \"{:20} from {:.2f} sec to {:.2f} sec, confidence is {:.2f}%\".format(\n",
    "            self.word, self.start, self.end, self.conf*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192384\n",
      "32000\n"
     ]
    }
   ],
   "source": [
    "#audio_filename = \"wav_examples/kaviar_sv.wav\"\n",
    "audio_filename = \"wav_examples/digitala_resurser_sv.wav\"\n",
    "#audio_filename = \"wav_examples/sammarbete_sv.wav\"\n",
    "wf = wave.open(audio_filename, \"rb\")\n",
    "\n",
    "print(wf.getnframes())\n",
    "print(wf.getframerate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "på                   from 0.66 sec to 0.84 sec, confidence is 100.00%\n",
      "många                from 0.84 sec to 1.14 sec, confidence is 100.00%\n",
      "skolor               from 1.14 sec to 1.77 sec, confidence is 100.00%\n",
      "saknas               from 1.80 sec to 2.52 sec, confidence is 100.00%\n",
      "såväl                from 2.52 sec to 2.88 sec, confidence is 100.00%\n",
      "digitala             from 2.88 sec to 3.60 sec, confidence is 100.00%\n",
      "som                  from 3.81 sec to 3.99 sec, confidence is 100.00%\n",
      "analoga              from 3.99 sec to 4.59 sec, confidence is 100.00%\n",
      "resurser             from 4.59 sec to 5.25 sec, confidence is 100.00%\n"
     ]
    }
   ],
   "source": [
    "wf = wave.open(audio_filename, \"rb\")\n",
    "\n",
    "rec = KaldiRecognizer(model, wf.getframerate())\n",
    "rec.SetWords(True)\n",
    "\n",
    "# get the list of JSON dictionaries\n",
    "results = []\n",
    "# recognize speech using vosk model\n",
    "while True:\n",
    "    data = wf.readframes(wf.getframerate())\n",
    "    if len(data) == 0:\n",
    "        break\n",
    "    if rec.AcceptWaveform(data):\n",
    "        part_result = json.loads(rec.Result())\n",
    "        results.append(part_result)\n",
    "part_result = json.loads(rec.FinalResult())\n",
    "results.append(part_result)\n",
    "\n",
    "\n",
    "# convert list of JSON dictionaries to list of 'Word' objects\n",
    "list_of_words = []\n",
    "for sentence in results:\n",
    "    if len(sentence) == 1:\n",
    "        # sometimes there are bugs in recognition \n",
    "        # and it returns an empty dictionary\n",
    "        # {'text': ''}\n",
    "        continue\n",
    "    for obj in sentence['result']:\n",
    "        w = Word(obj)  # create custom Word object\n",
    "        list_of_words.append(w)  # and add it to list\n",
    "\n",
    "#wf.close()  # close audiofile\n",
    "\n",
    "# output to the screen\n",
    "for word in list_of_words:\n",
    "    print(word.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HNR_peaks(audio, Fs):\n",
    "    tt = np.linspace(0, len(audio) / Fs, len(audio))\n",
    "    fl = int(0.05 * Fs)\n",
    "    frames, frames_start = split_frames(audio, fl, Fs, overlap=int(1 * fl / 8))\n",
    "    tt_frames_center = tt[frames_start] + int(fl/2)/Fs\n",
    "    hnr_frames = []\n",
    "    for f in frames:\n",
    "        hnr_frames.append(get_HNR(f, Fs, silence_threshold=0.5))\n",
    "    min_h = max(hnr_frames)/4\n",
    "    peaks, peaks_prop = signal.find_peaks(\n",
    "        hnr_frames,\n",
    "        height=min_h,\n",
    "        )\n",
    "    return frames, peaks_prop, peaks\n",
    "\n",
    "def checkVowels(word, vowels):\n",
    "    foundVowels = [letter for letter in word if letter in vowels]\n",
    "    return foundVowels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['å'], ['å', 'a'], ['o', 'o'], ['a', 'a'], ['å', 'ä'], ['i', 'i', 'a', 'a'], ['o'], ['a', 'a', 'o', 'a'], ['e', 'u', 'e']]\n"
     ]
    }
   ],
   "source": [
    "language = 'Swedish'\n",
    "vowels_sv = ['a', 'e', 'i','o','u','y','å','ä','ö']\n",
    "createLanguageFolder(language, vowels_sv)\n",
    "Fs, audio = wavfile.read(audio_filename)\n",
    "segments = []\n",
    "vowels = []\n",
    "for word in list_of_words:\n",
    "    if word.conf == 1:\n",
    "        vowels.append(checkVowels(word.word.lower(),vowels_sv))\n",
    "        start = round(word.start*Fs) #start of word\n",
    "        end = math.ceil(word.end*Fs + Fs/10) #end of word. Might need some fine-tuning\n",
    "        segments.append(audio[start:end]) #adding word to the list\n",
    "        path = 'test_timestamps/' + word.word + \".wav\" #path to save\n",
    "        wavfile.write(path, Fs, segments[-1]) #saving file in order to listen \n",
    "\n",
    "print(vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame length    : 1600 samples\n",
      "frame length    : 0.05 seconds\n",
      "number of frames: 6\n",
      "frame length    : 1600 samples\n",
      "frame length    : 0.05 seconds\n",
      "number of frames: 9\n",
      "Did not manage to identify all vowels from HNR\n",
      "frame length    : 1600 samples\n",
      "frame length    : 0.05 seconds\n",
      "number of frames: 16\n",
      "Did not manage to identify all vowels from HNR\n",
      "frame length    : 1600 samples\n",
      "frame length    : 0.05 seconds\n",
      "number of frames: 18\n",
      "Did not manage to identify all vowels from HNR\n",
      "frame length    : 1600 samples\n",
      "frame length    : 0.05 seconds\n",
      "number of frames: 10\n",
      "Did not manage to identify all vowels from HNR\n",
      "frame length    : 1600 samples\n",
      "frame length    : 0.05 seconds\n",
      "number of frames: 18\n",
      "frame length    : 1600 samples\n",
      "frame length    : 0.05 seconds\n",
      "number of frames: 6\n",
      "frame length    : 1600 samples\n",
      "frame length    : 0.05 seconds\n",
      "number of frames: 15\n",
      "frame length    : 1600 samples\n",
      "frame length    : 0.05 seconds\n",
      "number of frames: 17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(segments)) :\n",
    "    frames, peaks_prop, peaks = HNR_peaks(segments[i], Fs)\n",
    "    if len(peaks) == len(vowels[i]):\n",
    "        for j in range(len(peaks)):\n",
    "            updateFolder(language, frames[peaks[j]],vowels[i][j], vowels[i][j] + str(i) + str(j), Fs)\n",
    "            \n",
    "    else:\n",
    "        print(\"Did not manage to identify all vowels from HNR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
